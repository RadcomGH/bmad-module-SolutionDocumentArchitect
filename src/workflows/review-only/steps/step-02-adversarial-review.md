---
name: 'step-02-adversarial-review'
description: 'Client-Advocate and Product-Guard review document'
nextStepFile: './step-03-review-report.md'
---

# Step 2: Adversarial Review

## STEP GOAL

Conduct adversarial review from customer and R&D perspectives.

---

## EXECUTION

### 1. Review Initiation

"**Starting adversarial review...** üîç

The Review Board will now examine your document. Expect rigorous challenge‚Äîthis is how we make documents bulletproof."

---

### 2. CLIENT-ADVOCATE REVIEW (if included)

"**Client-Advocate Review: Customer Perspective** üßê

I'm reading this as a skeptical customer. Every claim will be challenged."

#### Review Dimensions:

**A. Clarity & Understanding**
- Can a customer understand this without technical background?
- Is jargon explained or is it assuming knowledge?
- Are concepts explained before they're used?
- Would a busy executive grasp the key points?

**Findings:**
{List clarity issues with specific examples and line/section references}

---

**B. Value Proposition**
- Is the business value clear and compelling?
- Are benefits concrete or vague marketing speak?
- Does it answer "Why should I care?"
- Are claims believable or do they sound too good to be true?

**Findings:**
{List value proposition issues}

---

**C. Credibility & Trust**
- Are technical claims backed up or just asserted?
- Are limitations and trade-offs acknowledged?
- Does it feel honest or like it's hiding problems?
- Would I trust this vendor/team based on this document?

**Findings:**
{List credibility issues}

---

**D. Completeness from Customer POV**
- What questions does a customer still have after reading?
- What's missing that customers need to know?
- Are risks and mitigation strategies addressed?
- Is pricing/cost mentioned (if applicable)?

**Findings:**
{List gaps from customer perspective}

---

**E. Call-to-Action & Next Steps**
- Is it clear what the customer should do next?
- Are next steps actionable?
- Is decision-making information provided?

**Findings:**
{List issues with CTA/next steps}

---

**Client-Advocate Summary:**

**Critical Issues:** {count} ‚Äî Must fix before publication
{list}

**High Priority:** {count} ‚Äî Should fix for better customer reception
{list}

**Medium Priority:** {count} ‚Äî Nice to improve
{list}

**What's Working Well:** {positive feedback}
{list}

---

### 3. PRODUCT-GUARD REVIEW (if included)

"**Product-Guard Review: R&D Perspective** üõ°Ô∏è

I'm validating technical accuracy and roadmap alignment. Every technical claim will be scrutinized."

#### Review Dimensions:

**A. Technical Accuracy**
- Are technical descriptions accurate?
- Are architecture claims correct?
- Are performance/scale numbers realistic?
- Are technology choices described correctly?

**Findings:**
{List accuracy issues with corrections}

---

**B. Feasibility & Roadmap Alignment**
- Can we actually deliver what's promised?
- Are claimed features on the roadmap?
- Are timelines realistic?
- Are we over-promising?

**Findings:**
{List feasibility concerns}

---

**C. Technical Completeness**
- Are architectural details sufficient for R&D understanding?
- Are dependencies documented?
- Are integration points clear?
- Are non-functional requirements addressed (security, performance, etc.)?

**Findings:**
{List technical gaps}

---

**D. Risk & Trade-off Disclosure**
- Are technical limitations honestly described?
- Are trade-offs explained?
- Are risks identified?
- Could this document come back to haunt us?

**Findings:**
{List risk disclosure issues}

---

**E. R&D Alignment**
- Would the engineering team support this document?
- Are we throwing engineering under the bus with unrealistic promises?
- Is technical complexity appropriately communicated?

**Findings:**
{List alignment issues}

---

**Product-Guard Summary:**

**Critical Issues:** {count} ‚Äî Must fix (technical accuracy errors, over-promising)
{list}

**High Priority:** {count} ‚Äî Should fix (technical gaps, alignment issues)
{list}

**Medium Priority:** {count} ‚Äî Consider improving
{list}

**What's Technically Sound:** {positive feedback}
{list}

---

### 4. Integrated Review Summary

"**Review Board Consensus:**

Client-Advocate and Product-Guard have completed their review. Here's where they agree:

**Shared Concerns:**
{Issues both reviewers identified}

**Tension Points:**
{Where Client-Advocate wants more clarity but Product-Guard defends technical accuracy, or vice versa}

**Overall Document Health:**
- üî¥ **Critical issues:** {count} ‚Äî Cannot publish without fixes
- üü† **High priority:** {count} ‚Äî Should fix before publication
- üü° **Medium priority:** {count} ‚Äî Would improve quality
- ‚úÖ **Strengths:** {what's working well}

**Recommendation:**
{publish with minor edits / needs revision / requires major rework}
"

### 5. User Reaction

"**How does this feedback land?**

- Surprising? Expected?
- Any specific findings you want to discuss?
- Ready to see the full review report?

Share your reaction or type 'continue':"

**Allow user to discuss specific findings or ask questions about review.**

### 6. Transition

"**Let me compile the complete review report with actionable recommendations.**"

### 7. Present Menu

**Select an Option:**
- **[C]** Continue to Review Report
- **[D]** Discuss specific finding
- **[R]** Re-review with different focus

---

## SUCCESS METRICS

‚úÖ Document reviewed from customer perspective (if included)
‚úÖ Document reviewed from R&D perspective (if included)
‚úÖ Issues categorized by severity
‚úÖ Positive feedback captured
‚úÖ User understands findings

---

_Step 2 of Review-Only Mode Workflow_